{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV/6qx4J1vsn5zWfXPPxql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emma922/Olist-Project/blob/main/Olist_EDA_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Exploratory Data Analysis & Data Cleaning â€“ Olist E-Commerce Dataset\n",
        "\n",
        "## 1. Introduction  \n",
        "This notebook performs a complete **Exploratory Data Analysis (EDA)** and **Data Cleaning** of the Olist e-commerce dataset.  \n",
        "The goal is to understand customer behavior, order patterns, payment habits, review performance, and product characteristics.\n",
        "\n",
        "We will:\n",
        "\n",
        "- Load all Olist datasets  \n",
        "- Explore structure, quality, missing data  \n",
        "- Clean and export the tables  \n",
        "- Understand correlations\n",
        "- Detect outliers  \n",
        "\n",
        "---\n",
        "\n",
        "# 2. Import Libraries\n"
      ],
      "metadata": {
        "id": "y_K7GevdSJae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eks8PE8CLUJq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "sns.set_theme()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load the Datasets\n",
        "\n",
        "Below is a description of each file:\n",
        "\n",
        "\n",
        "| File | Description |\n",
        "|------|-------------|\n",
        "| geolocation | Location + Lat/long data |\n",
        "| general_orders | Order details + Timestamps + Reviews |\n",
        "| orders | Order details + Timestamps + Reviews  |\n",
        "| products | Product info |\n",
        "| payments | Payment installments + value |\n",
        "| customers | Customers details |\n",
        "| sellers | Sellers details |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ESucoGqrcxDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "mjpqW43jmBdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geolocation = pd.read_csv(\"geolocation_olist_public_dataset.csv\")\n",
        "general_orders = pd.read_csv(\"olist_classified_public_dataset.csv\")\n",
        "orders = pd.read_csv(\"olist_public_dataset_v2.csv\")\n",
        "customers = pd.read_csv(\"olist_public_dataset_v2_customers.csv\")\n",
        "payments = pd.read_csv(\"payments_olist_public_dataset.csv\")\n",
        "products = pd.read_csv(\"product_measures_olist_public_dataset_.csv\")\n",
        "sellers = pd.read_csv(\"sellers_olist_public_dataset_.csv\")\n"
      ],
      "metadata": {
        "id": "UdR2IVoGiqVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preview & Raw Exploration\n",
        "\n",
        "We begin by inspecting the shape, structure, head, and summary of each dataset.\n"
      ],
      "metadata": {
        "id": "YIOgOe_lhYPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"======== {name.upper()} ========\")\n",
        "\n",
        "    display(df.head(3))\n",
        "\n",
        "    print(\"\\nInfo:\")\n",
        "    display(df.info())\n",
        "\n",
        "    print(\"\\nDescribe:\")\n",
        "    display(df.describe(include='all')\n",
        ")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zfiMrh2hokRc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Data Cleaning & Pre-processing"
      ],
      "metadata": {
        "id": "v586bJbnvHw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Missing values overview"
      ],
      "metadata": {
        "id": "TkBrzFPz17xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nNull count for {name}:\")\n",
        "    print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "yFLSrtEXu2xy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Missing Numeric Values\n",
        "- We'll look whether the dataset have missing values"
      ],
      "metadata": {
        "id": "oaxCRjet-2Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"===== {name.upper()} =====\")\n",
        "\n",
        "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    missing_numeric = df[numeric_cols].isna().sum()\n",
        "\n",
        "    print(\"Numeric columns with missing values:\")\n",
        "    print(missing_numeric[missing_numeric > 0])\n",
        "\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "gjn9sgod_CLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Outliers\n",
        "- An outlier analysis will be performed to identify unusually extreme values that could distort the results of the study.\n"
      ],
      "metadata": {
        "id": "WCbyQdgeAC7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    numeric_df = df.select_dtypes(include=[float, int])\n",
        "    corr = numeric_df.corr()\n",
        "\n",
        "    if corr.empty:\n",
        "        print(f\"\\nSkipping {name} because correlation matrix is empty or no numeric data.\")\n",
        "        continue\n",
        "\n",
        "    # Plot boxplot for numeric columns to detect outliers\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    numeric_df.boxplot()\n",
        "    plt.title(f'Boxplot for Numeric Columns of {name}')\n",
        "    plt.xticks(rotation=75)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "EfAYNQnvA2KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Duplicates Overview"
      ],
      "metadata": {
        "id": "rw0rFdlVUKVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "     \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nDuplicate rows for {name}:\")\n",
        "    duplicates = df[df.duplicated()]\n",
        "    if duplicates.empty:\n",
        "        print(\"No duplicate rows found.\")\n",
        "    else:\n",
        "        print(duplicates)\n"
      ],
      "metadata": {
        "id": "I4BhZBK6UVmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4.1 Handling Duplicates\n",
        "\n",
        "- No duplicate records were identified in the majority of the tables, indicating consistent and well-structured data across most datasets.\n",
        "\n",
        "- The geolocation table contains duplicate entries; however, these will be evaluated later during the SQL analysis to determine whether they represent legitimate repeated locations or redundant data.\n",
        "\n",
        "- Therefore, no duplicate removal has been applied at this stage, ensuring that no potentially relevant information is discarded prematurely."
      ],
      "metadata": {
        "id": "gE9bB9Y5YS7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Handling Missing values\n",
        "\n",
        "### Strategy:\n",
        "- Datetime columns: Missing timestamps are preserved because they often carry operational meaning (e.g., cancellations, unprocessed orders). Imputing or replace them may cause biased and unreal results\n",
        "\n",
        "- Categorical columns: Missing values are replaced with \"Unknown\" to maintain categorical integrity and avoid incorrect assumptions.\n",
        "\n",
        "- Numeric columns: Rare missing values are imputed with the median; if missingness is widespread and the column is not essential, the feature may be removed.\n",
        "\n",
        "- High-missingness irrelevant columns: Columns containing a high proportion of missing data and not neccesary to the analysis will be dropped\n",
        "\n"
      ],
      "metadata": {
        "id": "C4Y59axWzSbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.1 Drop unnecesary columns\n",
        "- Columns that won't be neccesary for the analysis and contain a high propotion of missing data\n"
      ],
      "metadata": {
        "id": "4S9UrxKi5kpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders = orders.drop(\n",
        "    columns=[\n",
        "        'product_name_lenght',\n",
        "        'product_description_lenght',\n",
        "        'product_photos_qty',\n",
        "        'review_comment_title',\n",
        "        'review_comment_message'\n",
        "    ]\n",
        ")\n",
        "\n",
        "general_orders = general_orders.drop(\n",
        "    columns=[\n",
        "        'product_name_lenght',\n",
        "        'product_description_lenght',\n",
        "        'product_photos_qty',\n",
        "        'review_comment_title',\n",
        "        'review_comment_message'\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "lv_3Y_Uv5htH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.2 Replace missing values\n",
        "- Missing values are replaced by 'unknown'\n"
      ],
      "metadata": {
        "id": "xBAL9dHl604R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_orders['most_voted_class'] = general_orders['most_voted_class'].fillna('unknown')\n",
        "\n",
        "general_orders['most_voted_subclass'] = general_orders['most_voted_subclass'].fillna('unknown')"
      ],
      "metadata": {
        "id": "tVKyakAw72wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.3 Replace or imput numeric missing values\n",
        "After reviewing all datasets, no numeric columns contain missing values across any of the tables. This indicates that:\n",
        "\n",
        "- All numeric attributes are fully populated\n",
        "\n",
        "- No median imputation is required\n",
        "\n",
        "- No numeric features need to be removed due to sparsity"
      ],
      "metadata": {
        "id": "PdEoy9r19ohe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mRu904Hw_69A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.4 Replace outliers with avg values\n",
        "\n",
        "- The boxplot analysis shows no presence of significant outliers across the numeric variables.\n",
        "\n",
        "- All detected values fall within expected and reasonable ranges for the dataset.\n",
        "\n",
        "- Although some variables contain large numerical values, a closer inspection shows that these values are consistent with the nature of the dataset and represent realistic business scenarios\n",
        "\n",
        "- Because of this, no outlier treatment is required"
      ],
      "metadata": {
        "id": "hMHlX851BzQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.5 Cleaning missings datetime values\n",
        "\n",
        "- Datetime features often carry important chronological patterns that are crucial for understanding customer behavior, delivery timelines, and order processing.\n",
        "\n",
        "- Imputing missing dates (e.g., filling with mean, median, or artificial timestamps) can introduce bias and create unreal or misleading sequences in the data.\n",
        "\n",
        "- For this reason, no imputation or replacement is applied to datetime columns.\n",
        "\n",
        "- Missing datetime values are kept as they are to preserve analytical integrity and avoid distorting time-based trends.\n"
      ],
      "metadata": {
        "id": "oIx4yDAIjbvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Correlations\n",
        "- The goal of this step is to identify the relationships between the variables within the dataset.\n",
        "\n",
        "- Understanding these correlations helps guide a more targeted and meaningful analysis, revealing how different features interact and potentially influence one another.\n",
        "\n",
        "- A correlation heatmap will be used to visually examine these relationships, allowing for a clearer interpretation of both the strength and direction of the associations."
      ],
      "metadata": {
        "id": "mo9pRfF_6f0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "     \"customers\": customers,\n",
        "    \"orders\": orders,\n",
        "    \"products\": products,\n",
        "    \"sellers\": sellers,\n",
        "    \"general_orders\": general_orders,\n",
        "    \"payments\": payments,\n",
        "    \"geolocation\": geolocation,\n",
        "}\n",
        "\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    numeric_df = df.select_dtypes(include=[float, int])\n",
        "    print(f\"\\nCorrelation matrix for {name}:\")\n",
        "    print(numeric_df.corr())\n",
        "\n"
      ],
      "metadata": {
        "id": "w3VzNfAF2-OQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Heatmap\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pkd3RiB7CGFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dfs.items():\n",
        "    numeric_df = df.select_dtypes(include=[float, int])\n",
        "    corr = numeric_df.corr()\n",
        "\n",
        "    if corr.empty:\n",
        "        print(f\"\\nSkipping {name} because correlation matrix is empty or no numeric data.\")\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(18,4))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title(f'Correlation Matrix Heatmap for {name}')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "R0CrAAkyCKBR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Heatmap Insights\n",
        "\n",
        "Overall, the dataset does not exhibit strong linear relationships among most variables, suggesting that the features operate largely independently and no single variable overwhelmingly drives another.\n",
        "\n",
        "A few moderate correlations are observed, which align with expected business logic:\n",
        "\n",
        "- Quantity of products, order value, and freight value show moderate relationships.\n",
        "This makes sense: larger orders tend to weigh more or require more volume, which can increase freight costs and total order value.\n",
        "\n",
        "- Review score is moderately correlated with votes_satisfied, indicating that higher customer satisfaction tends to be reflected in better ratings.\n",
        "\n",
        "- Product height and width correlate with product weight (grams), which is consistent with basic physical and volumetric characteristics of merchandise.\n",
        "\n",
        "These correlations, while not strong, provide useful signals that validate the internal consistency of the dataset and highlight logical patterns in customer orders, product attributes, and satisfaction metrics.\n"
      ],
      "metadata": {
        "id": "CwDdYfrve0Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Summary\n",
        "\n",
        "\n",
        "- Data Quality: The datasets overall exhibit good quality with manageable missing data and minimal duplicates.\n",
        "\n",
        "- Missing Data: While some missing values exist, particularly in datetime fields, these were preserved intentionally to avoid introducing bias through imputation or deletion. Categorical missing values, where appropriate, were replaced with 'unknown' to maintain dataset integrity.\n",
        "\n",
        "- Outliers: Exploratory visualizations such as boxplots revealed no significant outliers that could potentially distort analyses or modeling outcomes, indicating the dataset's consistency.\n",
        "\n",
        "- Duplicates: A thorough check showed few duplicate records in one dataset; these will be considered later in sql advanced analysis\n",
        "\n",
        "- Correlations: Correlation heatmaps highlighted moderate relationships among numeric variables, offering useful insights for further analysis.\n",
        "\n",
        "- Data Cleaning: Irrelevant or redundant columns with high missing rates or little analytical value were dropped.\n",
        "\n",
        "- Next Steps: The cleaned datasets are ready for advanced analysis, Tableau dashboards and reporting.\n",
        "This thorough cleaning and exploration forms a robust foundation for reliable and effective data-driven decision-making."
      ],
      "metadata": {
        "id": "g1xIjV3WnxZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Export data to csv"
      ],
      "metadata": {
        "id": "KT_CIijeDC--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "geolocation.to_csv('geolocation.csv', index=False)\n",
        "payments.to_csv('payments.csv', index=False)\n",
        "products.to_csv('products.csv', index=False)\n",
        "orders.to_csv('orders.csv', index=False)\n",
        "general_orders.to_csv('general_orders.csv', index=False)\n",
        "customers.to_csv('customers.csv', index=False)\n",
        "sellers.to_csv('sellers.csv', index=False)"
      ],
      "metadata": {
        "id": "yd-6n6BCDHGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('geolocation.csv')\n",
        "files.download('payments.csv')\n",
        "files.download('products.csv')\n",
        "files.download('orders.csv')\n",
        "files.download('general_orders.csv')\n",
        "files.download('customers.csv')\n",
        "files.download('sellers.csv')"
      ],
      "metadata": {
        "id": "N_NoMHxQHF3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}